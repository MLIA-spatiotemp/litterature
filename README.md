# spatiotemp_bib
Literature resources for spatiotemp

## Foundation Models

- [Poseidon: Efficient Foundation Models for PDEs](/papers/Herde2024_PoseidonEfficientFoundation.md) - [arxiv.org/abs/2405.19101](http://arxiv.org/abs/2405.19101)
- [Universal Physics Transformers: A Framework For Efficiently Scaling Neural Operators](/papers/Alkin2024_UniversalPhysicsTransformers.md) - [arxiv.org/abs/2402.12365](http://arxiv.org/abs/2402.12365)
- [UPS: Efficiently Building Foundation Models for PDE Solving via Cross-Modal Adaptation](/papers/Shen2024_UPSEfficientlyBuilding.md) - [arxiv.org/abs/2403.07187](http://arxiv.org/abs/2403.07187)
- [DPOT: Auto-Regressive Denoising Operator Transformer for Large-Scale PDE Pre-Training](/papers/Hao2024_DPOTAutoRegressiveDenoising.md) - [arxiv.org/abs/2403.03542v4](https://arxiv.org/abs/2403.03542v4)
- [Multiple Physics Pretraining for Physical Surrogate Models](/papers/McCabe2023_MultiplePhysicsPretraining.md) - [arxiv.org/abs/2310.02994](http://arxiv.org/abs/2310.02994)
- [Towards Foundation Models for Scientific Machine Learning: Characterizing Scaling and Transfer Behavior](/papers/Subramanian2023_FoundationModelsScientific.md) - [arxiv.org/abs/2306.00258](http://arxiv.org/abs/2306.00258)

â†’ [Synthesis](/notes/foundation_models.md)

## Team

- [GEPS: Boosting Generalization in Parametric PDE Neural Solvers through Adaptive Conditioning](/papers/Koupai2024_GEPSBoostingGeneralization.md)
- [Zebra: In-Context and Generative Pretraining for Solving Parametric PDEs](/papers/Serrano2024_ZebraInContextGenerative.md)
- [AROMA: Preserving Spatial Structure for Latent PDE Modeling with Local Neural Fields](/papers/Serrano2024_AROMAPreservingSpatial.md)
